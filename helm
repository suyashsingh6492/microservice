helm is going to follow a packaging format called Charts. Inside Helm, a chart is a collection of files that describes a related set of Kubernetes resources.
if you have 50 microservices, you can club all these 50 microservices related manifest files into a single component called Chart Inside Helm.
helm charts is, a chart can have a child charts or dependent charts as well,
Helm is a package manager for Kubernetes.
Package manager is a component that can help you in installing or uninstalling or upgrading your software packages. Just like how we have helm for Kubernetes,
like npm, pip,
we are going to create a single template.yaml file for the Service object regardless of how many microservices you have inside your cluster,
at some places it is trying to accept the dynamic values. whatever you mention inside this double curly braces is going to represent a dynamic value
Helm is going to support, release or version management as well, which means whenever needed, you can roll back your entire Kubernetes cluster to the previous working state with a single command.
https://helm.sh/docs/intro/install/
help ls , if empty  this is going to list all the religions or all the installations that we have done into the Kubernetes cluster with the help of Helm.
Helm is going to look for Kubernetes cluster connection details inside your local system. it is going to make an entry inside your system.
go to suyashkumarsingh (user) > hidden folder .kube > config> open file , you'll be able to see all the connection details that my kubectl right now is using to connect to my Kubernetes cluster.
click on using helm > helm search >
https://helm.sh/docs/intro/using_helm/
helm search hub wordpress  , we need to search if there are any WordPress related charts available inside the public repositories
above command will search for all WordPress charts on the artifact hub.
helm install happy-panda bitnami/wordpress , install wordpress , under the Bitnami repo.
Bitnami is a famous repository which maintains production ready helm charts     ,we need to make sure we have added the Bitnami repo details inside our local system.
first add into local repo like == helm repo add brigade https://brigadecore.github.io/charts
so to add bitnami : helm repo add bitnami https://charts.bitnami.com/bitnami.
 try to create your own helm chart or you try to use the third party helm chart, it is going to follow the predefined structure.
 chart.yaml.: chart.yaml file is going to have meta information about the helm chart.
 values.yaml: we need to maintain all the dynamic values that we want to inject at runtime into the template files
  sub folder is charts: will have other helm charts which my current chart is dependent on
  templates: maintain all the required Kubernetes manifest template Yaml files so into this template
helm ls > list of installations that we have done with the help of Helm.
help uninstall <name>
to create helm chart go to helms folder and type: helm create bank-common  ,to build a helm chart that is going to be act as a common chart for all my microservices.
delete all files inside templates folder, remove content of values.yaml ,
create 3 file inside templates, service.yaml: this is a helm template but not a Kubernetes manifest file
So first I'm trying to define a name for this entire template. using  define ,
whatever hyphens that you see at the starting and at the end, those are helpful to trim any space that you may have before and after of your statement.
we should also close that by using this end statement.
under the metadata name, I need to inject a dynamic value.  whoever is going to use this template Yaml file, they need to provide a service name inside their values.yaml.
So values is a helm framework object. So inside that values object keys and values that you have defined inside your values.yaml will be available and to access them.
And similarly, under the specification selector app we are using a key which is app label inside the Values object
in deployment.yaml file
Now, after defining all the container related properties, we should also try to inject environment variables that are required for my particular microservice.
inside helm we can write the if tag by using this if .values. app name enabled.
So if this boolean value has true, then this entire environment variable is going to be injected into the particular microservice deployment yaml file.
maybe there might be some microservice where I don't have to pass the property, which is spring application name.
So the key inside the config map is going to be the spring profiles active only.
So based upon this key inside the config map, my helm is going to look up for the value. The same is going to be assigned to this environment variable which is spring profiles active.
in configmap.yaml:
So I'm going to follow a standard like wherever I mentioned a prefix value as global. So that property name is going to be common for all microservices inside my microservice network.
So whoever is going to leverage this common helm chart, they are going to provide their own values.yaml
bank-services % helm create accounts  , delete all templates content  , delete valus.yaml content , go to chart.yaml
change version to 1.0.0, add dependency key please mention the version of helm chart of bank-common.
past the file in templates folder , I'm just trying to refer other template that I have defined with the name common.deployment.
 we have defined this template inside the bank-common helm chart? I'm simply trying to refer to the template available inside the other helm chart,
 Please make sure this dot is also present because this is a syntax that we need to follow. now check values.yml file
 these values.yaml like you can see first I'm trying to mention a key with the name deployment name.
 the service type here I'm mentioning the cluster IP because I don't want to expose my accounts microservice to the outside world.
  resource server enabled as false.
 The reason is inside my microservices only Gateway server is going to act as a resource server accounts  microservice is not an resource server.
 chart folder is empty now it is empty because we have not compiled our helm chart as of now.
 go inside accounts and type: helm dependencies build , compile successful ,
 copy account and paste as card and loans and others too
create new folder environments > inside it > helm create dev-env , delete template, and values.yaml content
add configmap.yaml in templates folder,
we already defined a config map template inside the bank-common helm chart with the name as common.configmap.
the prefix value that I have mentioned for all these values is global  But this is not a mandatory or a standard from helm.
This is a prefix that I want to maintain for my own understanding.
So here the host name has to be same as your service name that you have defined. So the service name that we have defined inside the service.yaml file of configserver is config
 we are going to set up all the third party components like Keycloak, Kafka and Grafana components with the helm charts only. In that process they are going to be deployed with the production standards.
 So when we follow those production standards, this is how our service name is going to be built inside
 ok for now go inside environments>dev-env and type : helm dependencies build

you may want to know how your Kubernetes manifest files is going to look like that are going to be generated by your helm chart.
helm template .  ,the same Kubernetes manifest files are also going to be installed inside your Kubernetes cluster.
this dot  I'm telling my helm template is available in this folder only.

 since we have made some changes inside the bank-common chart. We need to recompile all the charts where they have dependency on the bank-common.
to build all dependency from bank service folder
cd helms
cd bank-common/
helm dependencies build
cd ../bank-services
cd accounts
helm dependencies build
cd ../cards
helm dependencies build
cd ../configserver
helm dependencies build
cd ../eurekaserver
helm dependencies build
cd ../message
helm dependencies build
cd ../loans
helm dependencies build
cd ../gatewayserver
helm dependencies build
cd ../../environments/dev-env
helm dependencies build
cd ../../..


 if you want to install Kafka inside your Kubernetes cluster, you don't have to prepare the Kubernetes manifest files manually.
 Instead, you can rely on the helm charts available inside the web. bitnami
 https://github.com/bitnami/charts/tree/main/bitnami
 copy the zip file and extract it , past the key cloak folder
 If I try to run this Keycloak helm chart into my local Kubernetes cluster by default it is going to deploy my keycloak service with a cluster IP.
 But since I want to access my keyclock to create the client details and roles information, I'm going to expose my key clock service as a load balancer.
open keycloack>  value.yaml and search for ClusterIP and chagne it to   type: LoadBalancer
search for adminPassword
So whenever my admin password is empty behind the scenes, my keycloak helm chart is going to create a secret which will have some random password.
so give password ,
I'm going to run a helm command, which is helm install and what is the name that you want to give for your keycloak installation.
So once you have given some name to your release, you can mention what is the chart name or what is the folder name where your chart is present.
from helms folder > cd keycloak  , helm dependencies build
cd ..
helm install keycloak keycloak
follow the insturction to get the url

  export HTTP_SERVICE_PORT=$(kubectl get --namespace default -o jsonpath="{.spec.ports[?(@.name=='http')].port}" services keycloak)
    export SERVICE_IP=$(kubectl get svc --namespace default keycloak -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

    echo "http://${SERVICE_IP}:${HTTP_SERVICE_PORT}/"
now you will able to access url http://:80/ , or http://locahost:80
my keycloak also has dependency on other helm charts like Postgres because behind the scenes my keycloak is going to use Postgres database.

 this might you recieve in logs too
Keycloak can be accessed through the following DNS name from within your cluster:
    keycloak.default.svc.cluster.local (port 80)
So when we try to give these URL details to Gateway Server, it should be able to easily connect because my gateway server also is going to be deployed in the same Kubernetes cluster.

their might be memory problem > so go to docker > settings> resources > change cpu limit to 8 , memory to 12 gb,
run kubernative dashboard ui and check pods you will see keycloak is running
using  persistent volume claims, the pods can claim some space inside the worker nodes.
kubectl get pvc  , check all volums to delete pvc , kubectl delete pvc <name> ,
to install kafka, copy and paste kafka folder , go to value.yaml, set replicaCount =1
disable kafka security by SASL_PLAINTEXT. So this is the security protocol By default my Kafka is going to leverage.
change to PLAINTEXT,
go to kafka folder helm dependencies build , return back and run helm install kafka kafka, check logs and steps
So here in the output, you can see there is an information like each Kafka broker can be accessed by producers via Port 9092 by using the DNS name.
for rabbit change the poassword to guest , username to guest, in value.yaml
and change   type: ClusterIP to   type: LoadBalancer
for rabbitmq go to rabbitmq folder > helm dependencies build , cd .. , run> helm install rabbit rabbitmq
you will see message RabbitMQ can be accessed within the cluster on port 5672 at rabbit-rabbitmq.default.svc.cluster.local
http://localhost:15672/

to have prometheus > copy kube-prometheus ., open value.yaml , search for the additionalScrapeConfigs,
using these configs only my Prometheus will decide to scrape the metrics from the microservices.
change to  enabled: true, change     type: external to     type: internal
we need to provide the details of our microservices using which my Prometheus can connect with them and read the metrics of them
search for joblist and update it, see the value
go to kube-prometheus > helm dependencies build  , cd .. , helm install prometheus kube-prometheus
So by default Prometheus is set up with the help of cluster IP, so we cannot really access it.
But for some reason, if you want to access the same, So using the kubectl port forward command, we can temporarily expose a service.
mentioned in o/p logs too
     echo "Prometheus URL: http://127.0.0.1:9090/"
       kubectl port-forward --namespace default svc/prometheus-kube-prometheus-prometheus 9090:9090

 if you go to see the target http://127.0.0.1:9090/targets?search=  ,
 As of now, my accounts cards, config server, Eureka server all of them we didn't setup. That's why the status for all of them is showing as in red color.

So before we try to set up the actual Grafana, first we need to make sure we set up the loki and tempo. For the same,
copy grafana-tempo, grafana-loki into the folder ,
First, let me try to set up grafana-loki because loki is responsible to aggregate all the logs by my individual microservices.
So here you can see my loki has dependency on other charts like Memcached. That's why it is trying to download all those dependencies.
cd grafana-loki > helm dependencies build , cd .. , run> helm install loki grafana-loki
So this will install many components inside my Kubernetes cluster like ingested, distributor, querier, promtail, compactor, gateway.
Can you imagine setting up all these without helm chart?
Your Kubernetes administrator will need a lot of help from the developers and the Grafana admin to set
up these and it may need months of effort to have a proper setup, whereas with Helm it is super, super easy.
now
 cd grafana-tempo/ open value.yaml > search for otlp , So these are related to open telemetry configurations.
 So as of now you can see the open telemetry communication with the help of Http protocol and gRPC protocol is disabled.
 enable Then only the open telemetry Java agent that we have inside our individual microservices. It can send the tracing details to the tempo.

  cd grafana-tempo/ >  helm dependencies build , cd .. , run> helm install tempo grafana-tempo

 But here we have a problem, which is our individual microservices need a tempo url to which my open telemetry is going to send the details of tracing details.
type :  kubectl get services

So the service that our open telemetry should connect is these distributor. tempo-grafana-tempo-distributor
port no is 4317 ,
So this is how we are establishing a link between our individual microservice open telemetry with the grafana tempo.

now install grafana
open value.yaml file So let me open this inside this values.yaml I need to look for the information on how to provide the
data source Details of tempo Loki and Prometheus.
We can provide these data source details to grafana using Yaml configurations, or we can also manually set up the data sources from the UI of the Grafana.
search for datasources : secretDefinition , see the value self
So this is the DNS name of Prometheus inside my Kubernetes cluster.
So once we define these values now, my grafana should be able to connect with all the components related to Prometheus, loki and tempo.

cd grafana  > ls , cd .. , run> helm install grafana grafana
my Grafana is going to be exposed as a cluster IP service.
So whenever I have some requirements to debug any issues, my Kubernetes admin can run a command which is related to kubectl port forward.
  echo "Browse to http://127.0.0.1:8080"
    kubectl port-forward svc/grafana 8080:3000 &
Because we expose that traffic at the port 8080.
So Grafana internally is going to start at the port 3000. But here the traffic is going to be exposed at the port 8080.
 kubectl port-forward svc/grafana 3000:3000 &
 access using http://127.0.0.1:3000/login ,
 to get user name and password , open new terminal ,

    echo "User: admin"
    echo "Password: $(kubectl get secret grafana-admin --namespace default -o jsonpath="{.data.GF_SECURITY_ADMIN_PASSWORD}" | base64 -d)"
admin , cnHre1W40Z
go to http://127.0.0.1:3000/explore , you will see prometheus , loki , tempo

now helm ls, This will show you all the releases or all the installations or deployments that we have done with the help of Helm.

now go to cd environments
First, we need to decide under which environment we want to deploy our microservices. what is the chat name.: dev-env
so do : helm install <release name> <chart name>
helm install bank dev-env
you get the output deployed , let's go to the Kubernetes dashboard. on new terminal
kubectl -n kubernetes-dashboard port-forward svc/kubernetes-dashboard-kong-proxy 8443:443

so final is if want to reprocess then first >  helm uninstall bank

cd helms
cd bank-common/
helm dependencies build
cd ../bank-services
cd accounts
helm dependencies build
cd ../cards
helm dependencies build
cd ../configserver
helm dependencies build
cd ../eurekaserver
helm dependencies build
cd ../message
helm dependencies build
cd ../loans
helm dependencies build
cd ../gatewayserver
helm dependencies build
cd ../../environments/dev-env
helm dependencies build
cd ../../..
cd helms
cd keycloak
helm dependencies build
cd ..
cd kube-prometheus
helm dependencies build
cd ..
cd rabbitmq
helm dependencies build
cd ..
cd grafana-tempo
helm dependencies build
cd ..
cd grafana-loki
helm dependencies build
cd ..
cd grafana
helm dependencies build
cd ..
helm install rabbit rabbitmq
helm install keycloak keycloak
helm install prometheus grafana-prometheus
helm install loki grafana-loki
helm install tempo grafana-tempo
helm install grafana grafana
cd environments
helm install bank dev-env
cd ../..


we saw how to roll out and roll back changes with the help of Kubernetes and Kubectl Command.
helm upgrade <releasename> ,
before this after making changes do helm dependencies build
ex: cd helms/environments  , helm upgrade bank dev-env
So if I try to execute this, my helm is smart enough to identify what are the changes and deploy the same changes into the Kubernetes cluster. And it is also going to give the revision number as two.
The beauty of helm rollback is it is going to rollback your entire Kubernetes cluster components to the previous desired state.
Whereas with Kubectl, if you want to roll back, you need to roll back component by component.
helm history <release name>
helm history bank
So now think like we want to roll back to the previous working version, which is revision one
helm rollback bank 1
again type : helm history bank
you will see     dev-env-0.1.0   1.0.0           Rollback to 1

let me show you the what are all the installations that we have done with the help of helm. helm ls
then do
helm uninstall bank
helm uninstall grafana
helm uninstall tempo
helm uninstall loki
helm uninstall prometheus
helm uninstall rabbit
helm uninstall keycloak
helm ls
also delete persistentvolumeclaim manually

One of the famous product, which is a competitor for Helm is customize.
we have here is Helm template, and with the help of Helm Template Command,
we can try to render the all the Kubernetes manifest files that your helm is going to use behind the scenes







