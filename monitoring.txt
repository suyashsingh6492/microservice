because many containers and many services, they are going to generate the logs inside their own containers.
Sometimes your request may travel more than 20 microservices to give a response, so in such scenarios
it is going to be very tedious job to look for the logs inside the containers individually.
how we can combine all the logs from the multiple services into a centralized location.  how are we going to monitor performance of our service calls?
 call through the microservice network and see how long it took to complete at each microservice.
  it's not going to be a feasible option to monitor all the microservices 24 by seven.
 That's why we should automatically trigger some alerts and notifications, if there is some abnormal behavior inside a particular microservice.

 Observability is the ability to understand the internal state of a system by observing or by understanding its output.
  can be achieved by collecting and analyzing data from a variety of sources such as metrics, logs and traces.
  three pillars for observability. metric: cpu usage, memory usage and response times.
   we have is logs. :Logs are a record of events that occur inside a system.
  traces.: Traces are a record of the path that a request takes through a system inside our microservices network.

  Monitoring in microservice context involves checking the telemetry data available for the application and defining the alerts for known failure state.
  we can build some dashboards and build alerts and notifications based upon metrics, logs and traces information.
  If the CPU utilization of a particular container or a microservice crossed more than 80%, then I want a alert to be triggered.
  we can also track the health of our microservices. Using dashboards, alerts and notifications we can easily understand which
  microservice is underperforming or which microservice is having some network problems or any other kind
we can try to optimize our microservices by onboarding more number of instances or by killing the microservice, which is having problems.

Logs: logs contain a timestamp that indicates when the event happened, as well as the information about the event and its context.
    We should only log the severe events like there is an exception happened or there is an error happened inside production.
 So what is Grafana?:  if you want to implement log aggregating system, then go for the tool Grafana Loki.
  for tracing information you can leverage Grafana tempo.
  Grafana Loki is a horizontally scalable, highly available log aggregation system. It is designed to store any amount of logs from your microservices and applications.
  Alloy: responsible for scraping log lines,
  https://grafana.com/docs/loki/latest/get-started/quick-start/
  alloy to read the new logs whenever generated by the log app and collect the same logs and sent to loki
  In between there is an edge server like a gateway (nginx) .
  Inside Loki there are two components like Loki read component and Loki write component.
  Once my Loki component receives the logs, it is going to store the logs in a component with the name Minio.
  if one of the developer wants to understand the logs of a particular microservice. go to the grafana and he will try to search the logs
  request will go to the gateway  The gateway will forward the same request to the Loki read component  this log read component is going to read the logs from the minio and eventually
the same will be sent back to the Grafana

https://grafana.com/docs/loki/latest/get-started/quick-start/ , d
https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/docker-compose.yaml
in docker compose We are trying to tag to the network, which is Loki and we are also trying to create an alias name for this network Loki.
whenever we see & that indicates anchor. &loki-dns
we are trying to create a variable name, loki-dns we are trying to assign the value present under the networks.
    <<: *loki-dns we are going to merge this variable under this networks. With that, the same details that we have mentioned here will come under the write service as well.
/etc/alloy/config.alloy:ro  , read only config.alloy , don't change it
minio : create a directory inside the local host where we have this docker-compose.yml.  mkdir -p /data/loki-data
 to establish the link between Grafana and Loki. We need to provide this data source details to the grafana like where the Loki is deployed.
 gateway depend on read and write (loki read/loki write)
 flog we have a app with the name flog which will continuously generate some random logs.

 alloy related yml config
 https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/alloy-local-config.yaml
 alloy will read the log using socket unix:///var/run/docker.sock going to read the content from my docker containers with the help of the socket paths present inside all my containers
  the refresh interval is going to be five seconds
  whatever data my ally is going to read, I have defined with the help of regex
   That means I want my alloy to read all kind of logs data and the target label is going to be container.

 https://raw.githubusercontent.com/grafana/loki/main/examples/getting-started/loki-config.yaml
 make folder observability in docker compose folder.

 comment out redis related config
after starting all container go to http://localhost:3000/?orgId=1 
go to connection>data sources > http://localhost:3000/connections/datasources
click and check all connection detail mentioned in docker file. 
go to explore> select cotainer 
http://localhost:3000/explore
in promtail-local-config we define to take all log of container by regex 
in value you will see all container . select account-ms and run query
If needed, you can click on this live streaming with that any logs that are being generated behind by your accounts micro service container, they will immediately come here after every five seconds. 
search for bank-correlation-id in container, gateway-server-ms
all logs data save by minio service under .data folder in current dir you can see in docker compose vol secs. 

So to properly monitor our microservices, we need to understand metrics details like what is the
CPU usage, what is the memory usage, what is the heap dump usage, what are the threads, connections errors.
how to achieve this with the help of components like Spring Boot Actuator, Micrometer, Prometheus and Grafana?
first component that is responsible to generate the metrics inside a microservice instance is spring boot actuator.
my spring boot actuator is going to expose all the metrics related to the application.  /actuator/metrics
 Prometheus, : component which is responsible to extract and aggregate all the metrics from the microservices
 cannot understand the metrics provided by the actuator because actuator exposes the metrics information in a Json format which we can easily understand as
 humans, since the same format cannot be understand by the Prometheus, we need to use micrometer.
 Micrometer automatically exposes the actuator/metricsdata into a format that a particular monitoring system can understand.
 We have a design pattern with the name fact design pattern. It is going to deploy a front facing interface that will handle a lot of complexity behind the scenes.
 So this is very similar to SLF4J.
 With the help of Loki, we are trying to aggregate the logs, whereas with the help of Prometheus we are going to aggregate the metrics
   implementation 'io.micrometer:micrometer-registry-prometheus' add this dependency
   add in yml file   metrics: tags:application: ${spring.application.name} under management tag
 account microservice localhost:8085/actuator/metrics/system.cpu.usage ,
we add the dependency related to Micrometer and Prometheus inside our microservice, the micrometer
is going to expose a URL which is /actuator/prometheus.
 localhost:8085/actuator/prometheus
 o you can see here these are all the metrics, information which are present inside a format that that my Prometheus can understand.
 So my Prometheus is going to invoke this API path for every five seconds or every 10s or every one minute based upon your configurations inside the Prometheus.
 docker-compose>observability> prometheus
 Please fetch the metrics from the individual microservice containers every five seconds
 using the same metrics, try to evaluate and try to show the metrics inside the Prometheus dashboards for every five seconds.
 Under the static configs we need to mention what are the list of targets or what are the list of instances running under accounts microservice.
 here I'm not mentioning the local host because inside the Docker compose file the service name of accounts
 create a new service in docker-compose> default> , prometheus
 As a next step, we need to establish a link between Prometheus and Grafana.
 Previously with these Entrypoint command, we are trying to create a file with the name ds.yml.we have mentioned data source related to Loki
 I can create a folder inside the obserbility with the name Grafana.
 First, I'm trying to mention this API version one, which is a standard that we need to follow post
 that I'm going to delete any existing data sources with the same name like Prometheus and Loki.
 under this data source I have created two data source, one with the Prometheus and the second one is with the name Loki.
 to give some unique ID for this connection. uid.
 You can see using the volumes, I'm trying to copy the datasource.yml file into the container at this path.
 So the grafana is going to look for this and based upon the details that we have mentioned here, it is going to set up the connection details with the Loki and Prometheus.
open promethus url localhost:9090/targets/you should be able to see all the running containers information inside your Prometheus dashboard.
 go to graphs> search: cpu _usage, process_up, threads

 localhost:3000 , graphana , data source > loki and prometheus
 click search > select prometheus > search cpu
 So the Grafana is more matured project. It can help you to visualize your metrics better than Prometheus.
 go to prometheus > grafana> pre built dashboard click> search for jvm > macrometer >
 login grafana , admin , admin menu dashboard> new import> paste url> select prometheus data source>
 click on import > check and save , go back to website , search for spring boot > select spring boot system monitor

after login  go to grafana > alerting > alert rule> manage rule > create new rule 
http://localhost:3000/alerting/new/alerting 
rule type is Grafana manage, name : accounts, data source : prometheus because we want to trigger an alert based upon a metric available inside the Prometheus data source 
select metric up , label is job, value as account 
in ruduce option Based upon the last value, I want to generate a alert.
input is A , A means this is a query section where we have written and the mode we can leave it as strict. section C threasold whenever my value is below one, then I want to trigger an alert.Because whenever my application is up and running, the metric up will give the value as one.
Whereas if the microservice is down, the value is going to be zero.
3 point insert data in to folder, , name accounts, group is accounts too  Like how frequently
we want the alert to be evaluated by grafana. every 1 mins , or 5s  for 5mins, With this for 5m, we are telling to the grafana instead of throwing the alert at
the very first time, we want the grafana to monitor the alert for next to five minutes. change to 20s so pending period is 5s,
summary is do somting and save 
now go back to contact point > new > select integration as webhook 
go to https://hookdeck.com/ test sample webhook > create and paste the url, test connect , you will receive sample json as notification 
go to notification policy > change to deliver to webhook 
now stop you account service , now alert status changed to pending state , after 20 secs firing status  for every 10 sec it will fire , 
go to dashboard> new dashboard> setting > name: alert> save
add visualisation> query A prometheus , metric up , instance , accounts , 
visualisation is time series or select up , job, cards click on Alert tab> new alert rule you wll be redirect to same laert page
distributed tracing: understand and analyze the flow of requests as they propagate across multiple services
we should generate a unique identifier known as correlationId, which is going to generate for each request at the entry point of your distributed system or microservices.
because the developer has to visit each log present inside the microservice and he need to make sure he's appending the correlationId that is generated by the gateway server.
So this is going to be a super, super complex or challenging task.
three important components tags:  we can build a metadata that offer details like username of the authenticated user or the microservice identifier.
So if you attach these metadata information to the logs, you can easily identify from the log statement
to which microservice are to which metadata information that a particular log belongs.
A trace ID has to be generated at the starting of your request. Maybe when a request is trying to enter into your microservice network at the Edge server.
The same trace ID has to be attached to the all the logs that are associated to that request,
span ID? A span represents each individual stage of request processing.
For example, your request may travel accounts, loans and cards microservice.
under each service it should have its own span ID because inside accounts microservice you may invoke multiple methods and similarly inside other microservices
Spring Cloud Sleuth. When we try to implement distributed tracing with the help of Spring Cloud Sleuth.
logs they'll automatically have all the three components like metadata information, trace ID and the span ID.
we can integrate spring cloud sleuth with Zipkin.
not going to make any changes inside this project because they're trying to move all the tracing related changes into a common project called micrometer tracing.
micrometer tracing link that we have.
micrometer project. We also have capabilities to implement the distributed tracing.
Open telemetry is also going to do the same kind of job that micrometer can do in terms of distributed tracing.
micrometer library is specific to Java.
https://opentelemetry.io/docs/languages/java/
add dependency io.opentelemetry:opentelemetry-bom:1.42.0 ,
add in yml file inside logging   pattern:
                                   level: "%5p [${spring.application.name},%X{trace_id},%X{span_id}]"
I want to have my own custom pattern
%5p indicates I want to assign some five length characters before my application name.
this five length character Opentelemetry can try to generate some log severity, like whether the log is debug info or warning or error.
after bracket The very first one is tag.,
So my spring boot framework, whenever it is trying to generate a log statement, it will look for this
pattern and for these kind of dynamic information.
And accordingly it is going to append the same inside all my log statements that are going to be generated by my microservice.
my open telemetry at runtime It is going to inject application name trace ID and the span ID.
 open telemetry, also known as OTel.
 open telemetry is going to generate a trace information is, at runtime
 it is going to attach some byte code to your microservice application. Using the same byte code
 it is going to attach all the tracing information span information or any other metadata information.
use a component inside the Grafana ecosystem, which is tempo.
Just like Loki for logs and Prometheus for metrics. Similarly, using tempo, we are going to index all the tracing information.
This tempo again is a open source product, highly scalable and cost effective solution.
 So tempo is capable of only storing the tracing information.
 UI application which is going to connect to the tempo and display the same inside an UI page. That's where Grafana will come into picture.

in microservice-db-config , add env variable       JAVA_TOOL_OPTIONS: "-javaagent:/app/libs/opentelemetry-javaagent-1.33.5.jar"
OTEL_EXPORTER_OTLP_ENDPOINT: http://tempo:4317 OTEL_METRICS_EXPORTER: none
trying to pass Java agent parameter along with the path where my Opentelemetry jar is going to present.
So the Opentelemetry is going to send all the tracing related information to this tempo service
 I don't want to get metrics with the help of Opentelemetry because we already used a better tool whenever we are trying to export metrics, which is Prometheus.
 add into service configserver environment OTEL_SERVICE_NAME: "config-server" and same in other microservices
 create tempo configuration , create a new docker service tempo and add detail in grafana>datasource.yml
we are copying java agent jar in all microserices so it takes aournd 2mins, so add health check time
for all microservices interval: 20s and  retries: 20 from all 10,
after booting up docker compose , hit account crete, load create, cards create api
go to localhost:3000 > explore> logs info> you will see tempo in drop down , select loki ,
select accounts, search log will be like DEBUG  [accounts, b6f78ef228384fse,2f44026b4431]
center is trace id copy it and search it
go to tempo , and search trace id , you will see graph , gateway server then accounts with timing
into loans cards similar to this we have zipkin , jaeger
go to datasource> loki > derived fields we can try to tell to the Loki whenever it identifies some pattern,
it can try to derive a field and using that field we can try to link with other components inside the grafana.
add> traceid> regex is \[.+,(.+),.+\]    , internal link: tempo (datasource)
query is ${__value.raw}  say here is whatever value that we have extracted, the same we want to
pass as a query value to this TempoDataSource > save

go back to loki and search for the logs click on any logs you will see button tempo after clicking it will show the graph









